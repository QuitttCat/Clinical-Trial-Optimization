{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "******Classical QUBO solvers******"
      ],
      "metadata": {
        "id": "3tqVUjGaAHmG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install numpy\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def build_Q1(w: np.ndarray) -> np.ndarray:\n",
        "    #takes feature matrix as parameter,returns first discrepency term\n",
        "    n = w.shape[0]  #n denotes the total number of patient\n",
        "    w_sum = np.sum(w, axis=0)  # column sums\n",
        "    Q1 = np.zeros((n, n))\n",
        "\n",
        "    for i in range(n):\n",
        "        # Diagonal part\n",
        "        for s in range(3):\n",
        "            Q1[i, i] += 4 * (w[i, s]**2 - w[i, s] * w_sum[s])\n",
        "\n",
        "        # Off-diagonal part\n",
        "        for j in range(i + 1, n):\n",
        "            for s in range(3):\n",
        "                Q1[i, j] += 8 * w[i, s] * w[j, s]\n",
        "\n",
        "    return Q1\n",
        "\n",
        "def build_Q2(w: np.ndarray, rho: float = 0.5) -> np.ndarray:\n",
        "\n",
        "    n = w.shape[0]                   # number of patients\n",
        "    Q2 = np.zeros((n, n))            # initialize QUBO matrix\n",
        "\n",
        "    u = w**2                         # u[i, s] = w[i, s]^2\n",
        "    u_sum = np.sum(u, axis=0)\n",
        "\n",
        "    for i in range(n):\n",
        "        Q2[i, i] = rho * np.sum(4 * (u[i]**2 - u[i] * u_sum))\n",
        "\n",
        "\n",
        "    for i in range(n):\n",
        "        for j in range(i + 1, n):\n",
        "            Q2[i, j] = rho * np.sum(8 * u[i] * u[j])\n",
        "\n",
        "    return Q2\n",
        "\n",
        "def build_Q3(w: np.ndarray, rho: float = 0.5) -> np.ndarray:\n",
        "\n",
        "    n_samples, n_features = w.shape\n",
        "    Q3 = np.zeros((n_samples, n_samples))\n",
        "\n",
        "    # building all v_i^(ss') for s' > s and their sums over i\n",
        "    pair_list = []\n",
        "    for s in range(n_features):\n",
        "        for sp in range(s + 1, n_features):\n",
        "            pair_list.append((s, sp))\n",
        "\n",
        "    n_pairs = len(pair_list)\n",
        "    V = np.zeros((n_samples, n_pairs))\n",
        "    for idx, (s, sp) in enumerate(pair_list):\n",
        "        V[:, idx] = w[:, s] * w[:, sp]\n",
        "\n",
        "    v_total = np.sum(V, axis=0)  # v_Sigma^(ss') for each pair\n",
        "\n",
        "    # diagonal entries\n",
        "    for i in range(n_samples):\n",
        "        v_i = V[i]                       # all v_i^(ss')\n",
        "        Q3[i, i] = 2.0 * rho * np.sum(\n",
        "            4.0 * (v_i**2 - v_i * v_total)\n",
        "        )\n",
        "\n",
        "    # off-diagonal entries\n",
        "    for i in range(n_samples):\n",
        "        for j in range(i + 1, n_samples):\n",
        "            v_i = V[i]\n",
        "            v_j = V[j]\n",
        "            Q3[i, j] = 2.0 * rho * np.sum(\n",
        "                8.0 * v_i * v_j\n",
        "            )\n",
        "\n",
        "    return Q3\n",
        "\n",
        "def add_group_size_penalty(Q: np.ndarray, lam_size: float = 3.0) -> np.ndarray:\n",
        "\n",
        "    Q_new = Q.copy()\n",
        "    n = Q.shape[0]\n",
        "\n",
        "    # Diagonal contributions: lam_size * (1 - n)\n",
        "    for i in range(n):\n",
        "        Q_new[i, i] += lam_size * (1.0 - n)\n",
        "\n",
        "    # Off-diagonal contributions: 2 * lam_size for i < j\n",
        "    for i in range(n):\n",
        "        for j in range(i + 1, n):\n",
        "            Q_new[i, j] += 2.0 * lam_size\n",
        "\n",
        "    return Q_new\n",
        "\n",
        "\n",
        "\n",
        "def QUBO_formulation(W: np.ndarray,\n",
        "                     rho: float = 0.5 ,\n",
        "                     lam_size: float = 3.0,\n",
        "                     normalize: bool = True) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Combine Q1, Q2, Q3, then normalize and add the group-size penalty.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    W : np.ndarray of shape (n, d)\n",
        "        Feature matrix.\n",
        "    rho : float\n",
        "        Covariance weight used in Q2 and Q3.\n",
        "    lam_size : float\n",
        "        Penalty coefficient for the group-size constraint.\n",
        "    normalize : bool\n",
        "        If True, divide the discrepancy QUBO by its max absolute value\n",
        "        before adding the constraint penalty.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Q_final : np.ndarray of shape (n, n)\n",
        "        Final QUBO matrix.\n",
        "    \"\"\"\n",
        "\n",
        "    Q1 = build_Q1(W)\n",
        "    Q2 = build_Q2(W, rho)\n",
        "    Q3 = build_Q3(W, rho)\n",
        "\n",
        "    Q = Q1 + Q2 + Q3\n",
        "\n",
        "\n",
        "    if normalize:\n",
        "        max_abs = np.max(np.abs(Q))\n",
        "        if max_abs > 0.0:\n",
        "            Q = Q / max_abs\n",
        "\n",
        "    Q_final = add_group_size_penalty(Q, lam_size=lam_size)\n",
        "\n",
        "    return Q_final\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VMGrJkv5ATrw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ClinicalTrial:\n",
        "    rho: float  # Relative importance between first and second moments\n",
        "    w: np.ndarray  # Normalized patient covariates\n",
        "\n",
        "    def assert_valid(self, group1: np.ndarray, group2: np.ndarray) -> None:\n",
        "        \"\"\"\n",
        "        Checks if the patient constraints are met.\n",
        "\n",
        "        Arguments (where n is the number of patients):\n",
        "            - group1: np.ndarray(size = n) => Binary array of patients belonging to group 1\n",
        "            - group2: np.ndarray(size = n) => Binary array of patients belonging to group 2\n",
        "        Throws an AssertionError if the constraints are not met.\n",
        "        \"\"\"\n",
        "        group_size = int(self.w.shape[0] / 2)\n",
        "        # constraint 1: number of people in each group\n",
        "        assert (\n",
        "            np.sum(group1) == group_size\n",
        "        ), f\"Each group should have {group_size} patients\"\n",
        "        # contraint 2: every patient is in one group\n",
        "        assert (\n",
        "            group1 + group2 == 1\n",
        "        ).all(), \"Every patient needs to be assigned to one group\"\n",
        "\n",
        "    def discrepancy(self, group1: np.ndarray, group2: np.ndarray) -> float:\n",
        "        \"\"\"\n",
        "        Calculates discrepancy between patient groups.\n",
        "\n",
        "        Arguments (where n is the number of patients):\n",
        "            - group1: np.ndarray(size = n) => Binary array of patients belonging to group 1\n",
        "            - group2: np.ndarray(size = n) => Binary array of patients belonging to group 2\n",
        "        Returns:\n",
        "            - float => Value of discrepancy measure for group1 and group2\n",
        "        \"\"\"\n",
        "        # Check that all the constraints are being met\n",
        "        self.assert_valid(group1, group2)\n",
        "\n",
        "        # Order of the groups is arbitrary\n",
        "        if group1[0] == 0:\n",
        "            group1, group2 = group2, group1\n",
        "\n",
        "        n, r = self.w.shape\n",
        "\n",
        "        # Calculate mean values for each covariate\n",
        "        Mu = []\n",
        "        for i in range(r):\n",
        "            Mu.append(self.w[:, i].dot(group1 - group2) / n)\n",
        "\n",
        "        # Calculate second moments (variance and covariance)\n",
        "        Var_ii = []  # variance\n",
        "        Var_ij = []  # covariance\n",
        "\n",
        "        for i in range(r):\n",
        "            for j in range(i, r):\n",
        "                if i == j:\n",
        "                    Var_ii.append((self.w[:, i] ** 2).dot(group1 - group2) / n)\n",
        "                else:\n",
        "                    Var_ij.append(\n",
        "                        (self.w[:, i] * self.w[:, j]).dot(group1 - group2) / n\n",
        "                    )\n",
        "\n",
        "        # Calculate final discrepancy\n",
        "        discrepancy = (\n",
        "            np.sum(np.abs(Mu))\n",
        "            + self.rho * np.sum(np.abs(Var_ii))\n",
        "            + 2 * self.rho * np.sum(np.abs(Var_ij))\n",
        "        )\n",
        "        return discrepancy"
      ],
      "metadata": {
        "id": "OB8C3m97IjT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from io import StringIO\n",
        "import numpy as np\n",
        "\n",
        "w_data = \"\"\"\n",
        "-0.7650636535189481,0.283894442848472,-0.655816465582355\n",
        "-0.5856817886844943,1.2319371664692689,0.910198903115477\n",
        "-0.854754585936175,-0.3306700946565902,-0.054686355633081954\n",
        "0.22153660307055117,1.2078202901666337,-0.6382331351268004\n",
        "0.400918467905005,-0.04542566114612644,-0.4096498392045905\n",
        "-0.1372271265983581,0.47572063137057313,3.984424441638505\n",
        "-0.1372271265983581,-0.27827825993017496,0.1980740196655155\n",
        "0.8493731299911412,0.21597910153645256,-0.42613421150667297\n",
        "-0.7650636535189481,1.1249358532184994,-0.08325926762335818\n",
        "-0.1372271265983581,0.14113362335585988,1.382750909108507\n",
        "1.925664318997869,0.538646274137218,-0.372285261986537\n",
        "0.3112275354877781,0.29415104541396137,-0.20579310173550433\n",
        "0.7596821975739143,0.5652579997125404,-0.24150924172334964\n",
        "0.13184567065332425,-0.42297951774598436,-0.09809520269523238\n",
        "0.6699912651566874,-2.1402674337783933,0.40028231990439345\n",
        "-0.5856817886844943,-0.49948822877502536,-0.6052643905226355\n",
        "-0.1372271265983581,0.5788410679749358,-0.6909831264934643\n",
        "0.22153660307055117,-0.9424625774142155,3.0009667900962667\n",
        "-0.1372271265983581,-0.18458280946707206,1.9861888311800715\n",
        "1.1184459272428235,0.07848518606396536,-0.5876810600670809\n",
        "-0.5856817886844943,-1.5392859645357366,-0.23546497187925275\n",
        "-0.854754585936175,-1.0267330417360687,-0.41954046258584\n",
        "0.3112275354877781,1.6823960629265113,-0.12941551006918903\n",
        "-0.4959908562672674,1.1784365098438845,-0.0563347928632902\n",
        "-0.4062999238500389,-0.034060236681667924,-0.4140456718184792\n",
        "-0.4959908562672674,-1.010100713251496,-0.2310691392653641\n",
        "-0.9444455183534036,-1.2224401069045752,-0.3305248521545948\n",
        "0.8493731299911412,0.5339337810665824,2.334888253276789\n",
        "-0.5856817886844943,-1.79653264509717,-0.11128270053689834\n",
        "-0.4062999238500389,1.039279361522928,-0.439871188425075\n",
        "0.04215473823609734,0.7701128455475578,-0.3568998478379267\n",
        "-1.0341364507706305,1.2319371664692689,-0.2871160050924444\n",
        "-1.0341364507706305,-1.3943075012451869,-0.6431784468174251\n",
        "-0.9444455183534036,0.4901353160571981,-0.5448216920816665\n",
        "0.13184567065332425,1.948790524154465,0.25302192733912365\n",
        "2.19473711624955,1.742826856420469,-0.3865717179816751\n",
        "-0.047536194181131176,-0.05928593488327222,-0.6459258422011055\n",
        "0.13184567065332425,-1.2745547361562415,-0.628891990822287\n",
        "-0.6753727211017212,-0.0942138247008759,-0.39426442505598025\n",
        "-0.1372271265983581,0.7665091743759014,-0.790438839382695\n",
        "5.692683480521414,1.1975636876011444,-0.6415300095872168\n",
        "-0.1372271265983581,1.334780397598892,2.2075190032893652\n",
        "-0.1372271265983581,-1.042810959271162,3.1909766548316036\n",
        "-1.3929001804395398,-0.2976826431621845,-0.5349310687004171\n",
        "0.49060940032223355,-0.5690668029355032,-0.6343867815896478\n",
        "-0.854754585936175,0.5527837533491035,-0.4970170124056275\n",
        "0.3112275354877781,-0.17515782332581153,-0.298105586627166\n",
        "0.400918467905005,0.5200735073294374,-0.25854309310216816\n",
        "0.22153660307055117,0.12422408939654765,-0.4662461841084069\n",
        "-0.854754585936175,0.5333793701171032,-0.09864468177196847\n",
        "2.2844280486667783,-0.7370533206297188,-0.2129363297330734\n",
        "-1.1238273831878574,0.1691313763049011,-0.5266888825493758\n",
        "2.19473711624955,1.1448946473999888,-0.6602122981962437\n",
        "-0.047536194181131176,0.5769006296517378,-0.40855088105111836\n",
        "-0.5856817886844943,2.2354209850386475,-0.5948242880646499\n",
        "-0.1372271265983581,1.00906396477596,-0.34371234999626077\n",
        "2.015355251415096,-0.4933897083306817,-0.5635039806906933\n",
        "0.7596821975739143,-0.41161409328152654,1.9673966467556976\n",
        "-0.4959908562672674,-2.2081827750904024,0.03377977572142715\n",
        "-0.5856817886844943,-1.0563940275335575,-0.25854309310216816\n",
        "1.1184459272428235,0.822504680273963,-0.5497670037722913\n",
        "0.3112275354877781,-0.7772481144674374,0.16070944244746196\n",
        "-0.6753727211017212,0.161369623012099,1.1431780316515756\n",
        "-0.5856817886844943,0.5949189855100293,-0.642628967740689\n",
        "-0.5856817886844943,1.2100379339645713,-0.6805430240354787\n",
        "0.5803003327394605,0.17717033507244279,-0.40250661120702147\n",
        "-1.2135183156050844,-1.703946016533026,-0.2920613167830691\n",
        "-0.7650636535189481,-0.9915279464437146,0.83546974867937\n",
        "-1.1238273831878574,-0.9455118376363927,0.07938653909052192\n",
        "-0.1372271265983581,-0.6713556231156471,-0.5558112736163882\n",
        "-0.31660899143281196,1.0620102104518552,-0.5596576271535407\n",
        "0.04215473823609734,-1.776019439966191,0.16455579598461453\n",
        "-0.5856817886844943,0.805317940839901,-0.026113443642805722\n",
        "0.22153660307055117,-0.11472702983185462,0.03597769202837148\n",
        "0.8493731299911412,-1.3275009818321366,-0.43217848135076986\n",
        "-0.854754585936175,-2.067362393920999,-0.22667330665147542\n",
        "-0.5856817886844943,-0.6142512953185962,-0.3579988059913989\n",
        "-0.047536194181131176,-0.964361809918913,-0.33601964292195563\n",
        "-0.854754585936175,-0.08340281118590664,-0.4310795231972977\n",
        "-0.5856817886844943,-1.629932154776673,-0.5047097194799326\n",
        "-0.854754585936175,1.709007788501833,-0.47009253764555947\n",
        "0.22153660307055117,1.058960950229678,-0.6250456372851344\n",
        "-1.0341364507706305,-0.8049686619417282,-0.46789462133861515\n",
        "-0.4959908562672674,1.955166250073549,-0.6321888652827035\n",
        "-0.4062999238500389,0.2248496767282231,-0.2931602749365413\n",
        "0.22153660307055117,-0.15769387841701005,4.715231613697493\n",
        "-0.9444455183534036,0.4934617817541149,-0.6332878234361756\n",
        "-0.22691805901558504,-0.5552065291983574,-0.27942329801813925\n",
        "-0.854754585936175,-1.2448937503587518,-0.6272435535920787\n",
        "1.477209656911733,-0.44848242142232825,0.2717042159481504\n",
        "-0.1372271265983581,-0.7722584159220621,1.8509070824876483\n",
        "1.1184459272428235,0.30579367535315943,-0.39096755059556376\n",
        "-0.6753727211017212,0.34238479801922156,0.16730319136829494\n",
        "-0.7650636535189481,-0.6835526640043345,0.18268860551690522\n",
        "0.400918467905005,-0.6635938698228451,0.052462064330453924\n",
        "1.925664318997869,1.5379720105854517,-0.6102097022132602\n",
        "-0.4062999238500389,-0.17377179595209344,-0.16458217098029823\n",
        "1.387518724494506,0.6583990392261534,-0.5497670037722913\n",
        "-0.31660899143281196,-0.8227098123252801,-0.10249103530912104\n",
        "0.7596821975739143,0.6425983271658103,-0.5525143991559717\n",
        "\"\"\"\n",
        "\n",
        "w = np.loadtxt(StringIO(w_data), delimiter=\",\")\n",
        "print(w[0])   # (100, 3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "SyaHU2R4c6tJ",
        "outputId": "10d72906-da85-4c74-f389-f27de25b3913"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.76506365  0.28389444 -0.65581647]\n",
            " [-0.58568179  1.23193717  0.9101989 ]\n",
            " [-0.85475459 -0.33067009 -0.05468636]\n",
            " [ 0.2215366   1.20782029 -0.63823314]\n",
            " [ 0.40091847 -0.04542566 -0.40964984]\n",
            " [-0.13722713  0.47572063  3.98442444]\n",
            " [-0.13722713 -0.27827826  0.19807402]\n",
            " [ 0.84937313  0.2159791  -0.42613421]\n",
            " [-0.76506365  1.12493585 -0.08325927]\n",
            " [-0.13722713  0.14113362  1.38275091]\n",
            " [ 1.92566432  0.53864627 -0.37228526]\n",
            " [ 0.31122754  0.29415105 -0.2057931 ]\n",
            " [ 0.7596822   0.565258   -0.24150924]\n",
            " [ 0.13184567 -0.42297952 -0.0980952 ]\n",
            " [ 0.66999127 -2.14026743  0.40028232]\n",
            " [-0.58568179 -0.49948823 -0.60526439]\n",
            " [-0.13722713  0.57884107 -0.69098313]\n",
            " [ 0.2215366  -0.94246258  3.00096679]\n",
            " [-0.13722713 -0.18458281  1.98618883]\n",
            " [ 1.11844593  0.07848519 -0.58768106]\n",
            " [-0.58568179 -1.53928596 -0.23546497]\n",
            " [-0.85475459 -1.02673304 -0.41954046]\n",
            " [ 0.31122754  1.68239606 -0.12941551]\n",
            " [-0.49599086  1.17843651 -0.05633479]\n",
            " [-0.40629992 -0.03406024 -0.41404567]\n",
            " [-0.49599086 -1.01010071 -0.23106914]\n",
            " [-0.94444552 -1.22244011 -0.33052485]\n",
            " [ 0.84937313  0.53393378  2.33488825]\n",
            " [-0.58568179 -1.79653265 -0.1112827 ]\n",
            " [-0.40629992  1.03927936 -0.43987119]\n",
            " [ 0.04215474  0.77011285 -0.35689985]\n",
            " [-1.03413645  1.23193717 -0.28711601]\n",
            " [-1.03413645 -1.3943075  -0.64317845]\n",
            " [-0.94444552  0.49013532 -0.54482169]\n",
            " [ 0.13184567  1.94879052  0.25302193]\n",
            " [ 2.19473712  1.74282686 -0.38657172]\n",
            " [-0.04753619 -0.05928593 -0.64592584]\n",
            " [ 0.13184567 -1.27455474 -0.62889199]\n",
            " [-0.67537272 -0.09421382 -0.39426443]\n",
            " [-0.13722713  0.76650917 -0.79043884]\n",
            " [ 5.69268348  1.19756369 -0.64153001]\n",
            " [-0.13722713  1.3347804   2.207519  ]\n",
            " [-0.13722713 -1.04281096  3.19097665]\n",
            " [-1.39290018 -0.29768264 -0.53493107]\n",
            " [ 0.4906094  -0.5690668  -0.63438678]\n",
            " [-0.85475459  0.55278375 -0.49701701]\n",
            " [ 0.31122754 -0.17515782 -0.29810559]\n",
            " [ 0.40091847  0.52007351 -0.25854309]\n",
            " [ 0.2215366   0.12422409 -0.46624618]\n",
            " [-0.85475459  0.53337937 -0.09864468]\n",
            " [ 2.28442805 -0.73705332 -0.21293633]\n",
            " [-1.12382738  0.16913138 -0.52668888]\n",
            " [ 2.19473712  1.14489465 -0.6602123 ]\n",
            " [-0.04753619  0.57690063 -0.40855088]\n",
            " [-0.58568179  2.23542099 -0.59482429]\n",
            " [-0.13722713  1.00906396 -0.34371235]\n",
            " [ 2.01535525 -0.49338971 -0.56350398]\n",
            " [ 0.7596822  -0.41161409  1.96739665]\n",
            " [-0.49599086 -2.20818278  0.03377978]\n",
            " [-0.58568179 -1.05639403 -0.25854309]\n",
            " [ 1.11844593  0.82250468 -0.549767  ]\n",
            " [ 0.31122754 -0.77724811  0.16070944]\n",
            " [-0.67537272  0.16136962  1.14317803]\n",
            " [-0.58568179  0.59491899 -0.64262897]\n",
            " [-0.58568179  1.21003793 -0.68054302]\n",
            " [ 0.58030033  0.17717034 -0.40250661]\n",
            " [-1.21351832 -1.70394602 -0.29206132]\n",
            " [-0.76506365 -0.99152795  0.83546975]\n",
            " [-1.12382738 -0.94551184  0.07938654]\n",
            " [-0.13722713 -0.67135562 -0.55581127]\n",
            " [-0.31660899  1.06201021 -0.55965763]\n",
            " [ 0.04215474 -1.77601944  0.1645558 ]\n",
            " [-0.58568179  0.80531794 -0.02611344]\n",
            " [ 0.2215366  -0.11472703  0.03597769]\n",
            " [ 0.84937313 -1.32750098 -0.43217848]\n",
            " [-0.85475459 -2.06736239 -0.22667331]\n",
            " [-0.58568179 -0.6142513  -0.35799881]\n",
            " [-0.04753619 -0.96436181 -0.33601964]\n",
            " [-0.85475459 -0.08340281 -0.43107952]\n",
            " [-0.58568179 -1.62993215 -0.50470972]\n",
            " [-0.85475459  1.70900779 -0.47009254]\n",
            " [ 0.2215366   1.05896095 -0.62504564]\n",
            " [-1.03413645 -0.80496866 -0.46789462]\n",
            " [-0.49599086  1.95516625 -0.63218887]\n",
            " [-0.40629992  0.22484968 -0.29316027]\n",
            " [ 0.2215366  -0.15769388  4.71523161]\n",
            " [-0.94444552  0.49346178 -0.63328782]\n",
            " [-0.22691806 -0.55520653 -0.2794233 ]\n",
            " [-0.85475459 -1.24489375 -0.62724355]\n",
            " [ 1.47720966 -0.44848242  0.27170422]\n",
            " [-0.13722713 -0.77225842  1.85090708]\n",
            " [ 1.11844593  0.30579368 -0.39096755]\n",
            " [-0.67537272  0.3423848   0.16730319]\n",
            " [-0.76506365 -0.68355266  0.18268861]\n",
            " [ 0.40091847 -0.66359387  0.05246206]\n",
            " [ 1.92566432  1.53797201 -0.6102097 ]\n",
            " [-0.40629992 -0.1737718  -0.16458217]\n",
            " [ 1.38751872  0.65839904 -0.549767  ]\n",
            " [-0.31660899 -0.82270981 -0.10249104]\n",
            " [ 0.7596822   0.64259833 -0.5525144 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(w.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNI4JnVxedns",
        "outputId": "e877c2e7-8c5c-4a14-b05e-830f4b36162b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_patients , n_covariates = w.shape\n",
        "rho = 0.5\n",
        "\n",
        "trial = ClinicalTrial()\n",
        "trial.w = w\n",
        "trial.rho = rho\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "E8iT2v7Dc_sW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Complete QUBO Pipeline for Patient Group Matching\n",
        "==================================================\n",
        "\n",
        "Dependencies:\n",
        "    pip install numpy torch\n",
        "\n",
        "Hardware:\n",
        "    - GPU recommended (CUDA-enabled for faster solving)\n",
        "    - CPU fallback available\n",
        "\n",
        "Usage:\n",
        "    W = np.random.randn(100, 3)  # Your feature matrix\n",
        "    group1, group2 = solve_patient_matching(W, rho=0.5, lam_size=3.0)\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import time\n",
        "from typing import Tuple, Dict, List\n",
        "\n",
        "# ============================================================================\n",
        "# PART 1: QUBO FORMULATION\n",
        "# ============================================================================\n",
        "\n",
        "def build_Q1(w: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Build first discrepancy term for mean matching.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    w : np.ndarray of shape (n, d)\n",
        "        Feature matrix\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    Q1 : np.ndarray of shape (n, n)\n",
        "        First QUBO term\n",
        "    \"\"\"\n",
        "    n = w.shape[0]\n",
        "    w_sum = np.sum(w, axis=0)\n",
        "    Q1 = np.zeros((n, n))\n",
        "\n",
        "    for i in range(n):\n",
        "        # Diagonal part\n",
        "        for s in range(w.shape[1]):\n",
        "            Q1[i, i] += 4 * (w[i, s]**2 - w[i, s] * w_sum[s])\n",
        "\n",
        "        # Off-diagonal part\n",
        "        for j in range(i + 1, n):\n",
        "            for s in range(w.shape[1]):\n",
        "                Q1[i, j] += 8 * w[i, s] * w[j, s]\n",
        "\n",
        "    return Q1\n",
        "\n",
        "\n",
        "def build_Q2(w: np.ndarray, rho: float = 0.5) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Build second discrepancy term for variance matching.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    w : np.ndarray of shape (n, d)\n",
        "        Feature matrix\n",
        "    rho : float\n",
        "        Weight for variance term\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    Q2 : np.ndarray of shape (n, n)\n",
        "        Second QUBO term\n",
        "    \"\"\"\n",
        "    n = w.shape[0]\n",
        "    Q2 = np.zeros((n, n))\n",
        "\n",
        "    u = w**2\n",
        "    u_sum = np.sum(u, axis=0)\n",
        "\n",
        "    for i in range(n):\n",
        "        Q2[i, i] = rho * np.sum(4 * (u[i]**2 - u[i] * u_sum))\n",
        "\n",
        "    for i in range(n):\n",
        "        for j in range(i + 1, n):\n",
        "            Q2[i, j] = rho * np.sum(8 * u[i] * u[j])\n",
        "\n",
        "    return Q2\n",
        "\n",
        "\n",
        "def build_Q3(w: np.ndarray, rho: float = 0.5) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Build third discrepancy term for covariance matching.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    w : np.ndarray of shape (n, d)\n",
        "        Feature matrix\n",
        "    rho : float\n",
        "        Weight for covariance term\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    Q3 : np.ndarray of shape (n, n)\n",
        "        Third QUBO term\n",
        "    \"\"\"\n",
        "    n_samples, n_features = w.shape\n",
        "    Q3 = np.zeros((n_samples, n_samples))\n",
        "\n",
        "    # Build all v_i^(ss') for s' > s\n",
        "    pair_list = []\n",
        "    for s in range(n_features):\n",
        "        for sp in range(s + 1, n_features):\n",
        "            pair_list.append((s, sp))\n",
        "\n",
        "    n_pairs = len(pair_list)\n",
        "    V = np.zeros((n_samples, n_pairs))\n",
        "    for idx, (s, sp) in enumerate(pair_list):\n",
        "        V[:, idx] = w[:, s] * w[:, sp]\n",
        "\n",
        "    v_total = np.sum(V, axis=0)\n",
        "\n",
        "    # Diagonal entries\n",
        "    for i in range(n_samples):\n",
        "        v_i = V[i]\n",
        "        Q3[i, i] = 2.0 * rho * np.sum(4.0 * (v_i**2 - v_i * v_total))\n",
        "\n",
        "    # Off-diagonal entries\n",
        "    for i in range(n_samples):\n",
        "        for j in range(i + 1, n_samples):\n",
        "            v_i = V[i]\n",
        "            v_j = V[j]\n",
        "            Q3[i, j] = 2.0 * rho * np.sum(8.0 * v_i * v_j)\n",
        "\n",
        "    return Q3\n",
        "\n",
        "\n",
        "def add_group_size_penalty(Q: np.ndarray, lam_size: float = 3.0) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Add penalty for group size constraint (encouraging equal split).\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    Q : np.ndarray of shape (n, n)\n",
        "        QUBO matrix\n",
        "    lam_size : float\n",
        "        Penalty coefficient\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    Q_new : np.ndarray of shape (n, n)\n",
        "        QUBO with penalty\n",
        "    \"\"\"\n",
        "    Q_new = Q.copy()\n",
        "    n = Q.shape[0]\n",
        "\n",
        "    for i in range(n):\n",
        "        Q_new[i, i] += lam_size * (1.0 - n)\n",
        "\n",
        "    for i in range(n):\n",
        "        for j in range(i + 1, n):\n",
        "            Q_new[i, j] += 2.0 * lam_size\n",
        "\n",
        "    return Q_new\n",
        "\n",
        "\n",
        "def QUBO_formulation(W: np.ndarray,\n",
        "                     rho: float = 0.5,\n",
        "                     lam_size: float = 3.0,\n",
        "                     normalize: bool = True) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Complete QUBO formulation combining all terms.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    W : np.ndarray of shape (n, d)\n",
        "        Feature matrix\n",
        "    rho : float\n",
        "        Covariance weight\n",
        "    lam_size : float\n",
        "        Group size penalty coefficient\n",
        "    normalize : bool\n",
        "        Whether to normalize before adding penalty\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    Q_final : np.ndarray of shape (n, n)\n",
        "        Final QUBO matrix\n",
        "    \"\"\"\n",
        "    Q1 = build_Q1(W)\n",
        "    Q2 = build_Q2(W, rho)\n",
        "    Q3 = build_Q3(W, rho)\n",
        "\n",
        "    Q = Q1 + Q2 + Q3\n",
        "\n",
        "    if normalize:\n",
        "        max_abs = np.max(np.abs(Q))\n",
        "        if max_abs > 0.0:\n",
        "            Q = Q / max_abs\n",
        "\n",
        "    Q_final = add_group_size_penalty(Q, lam_size=lam_size)\n",
        "\n",
        "    return Q_final\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# PART 2: SOLVERS\n",
        "# ============================================================================\n",
        "\n",
        "class QUBOSimulatedAnnealing:\n",
        "    \"\"\"GPU-accelerated Simulated Annealing for QUBO problems.\"\"\"\n",
        "\n",
        "    def __init__(self, Q: np.ndarray, device='cuda'):\n",
        "        self.n = Q.shape[0]\n",
        "        self.device = torch.device(device if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "        Q_sym = Q + Q.T - np.diag(np.diag(Q))\n",
        "        self.Q = torch.from_numpy(Q_sym).float().to(self.device)\n",
        "\n",
        "    def energy(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Compute QUBO energy: x^T Q x\"\"\"\n",
        "        if x.dim() == 1:\n",
        "            return x @ self.Q @ x\n",
        "        else:\n",
        "            return torch.sum(x * (x @ self.Q), dim=-1)\n",
        "\n",
        "    def solve(self,\n",
        "              n_iterations: int = 10000,\n",
        "              T_initial: float = 100.0,\n",
        "              T_final: float = 0.01,\n",
        "              n_parallel: int = 64,\n",
        "              verbose: bool = False) -> Tuple[np.ndarray, float]:\n",
        "\n",
        "        x = torch.randint(0, 2, (n_parallel, self.n),\n",
        "                         dtype=torch.float32, device=self.device)\n",
        "\n",
        "        current_energy = self.energy(x)\n",
        "        best_x = x.clone()\n",
        "        best_energy = current_energy.clone()\n",
        "\n",
        "        alpha = (T_final / T_initial) ** (1.0 / n_iterations)\n",
        "        T = T_initial\n",
        "\n",
        "        for iteration in range(n_iterations):\n",
        "            flip_idx = torch.randint(0, self.n, (n_parallel,), device=self.device)\n",
        "            x_new = x.clone()\n",
        "            x_new[torch.arange(n_parallel), flip_idx] = 1 - x_new[torch.arange(n_parallel), flip_idx]\n",
        "\n",
        "            new_energy = self.energy(x_new)\n",
        "            delta_E = new_energy - current_energy\n",
        "\n",
        "            accept_prob = torch.exp(-delta_E / T)\n",
        "            accept = (delta_E < 0) | (torch.rand(n_parallel, device=self.device) < accept_prob)\n",
        "\n",
        "            x = torch.where(accept.unsqueeze(1), x_new, x)\n",
        "            current_energy = torch.where(accept, new_energy, current_energy)\n",
        "\n",
        "            improved = current_energy < best_energy\n",
        "            best_x = torch.where(improved.unsqueeze(1), x, best_x)\n",
        "            best_energy = torch.where(improved, current_energy, best_energy)\n",
        "\n",
        "            T *= alpha\n",
        "\n",
        "            if verbose and iteration % 2000 == 0:\n",
        "                print(f\"  Iteration {iteration}, Best Energy={best_energy.min().item():.4f}\")\n",
        "\n",
        "        best_idx = torch.argmin(best_energy)\n",
        "        return best_x[best_idx].cpu().numpy().astype(int), best_energy[best_idx].item()\n",
        "\n",
        "\n",
        "class QUBOTabuSearch:\n",
        "    \"\"\"Tabu Search for QUBO problems.\"\"\"\n",
        "\n",
        "    def __init__(self, Q: np.ndarray):\n",
        "        self.Q = Q + Q.T - np.diag(np.diag(Q))\n",
        "        self.n = Q.shape[0]\n",
        "\n",
        "    def energy(self, x: np.ndarray) -> float:\n",
        "        return x @ self.Q @ x\n",
        "\n",
        "    def solve(self,\n",
        "              max_iterations: int = 5000,\n",
        "              tabu_tenure: int = 10,\n",
        "              n_restarts: int = 5,\n",
        "              verbose: bool = False) -> Tuple[np.ndarray, float]:\n",
        "\n",
        "        global_best_x = None\n",
        "        global_best_energy = float('inf')\n",
        "\n",
        "        for restart in range(n_restarts):\n",
        "            if verbose:\n",
        "                print(f\"  Restart {restart+1}/{n_restarts}\")\n",
        "\n",
        "            x = np.random.randint(0, 2, self.n)\n",
        "            current_energy = self.energy(x)\n",
        "\n",
        "            best_x = x.copy()\n",
        "            best_energy = current_energy\n",
        "\n",
        "            tabu_list = {}\n",
        "\n",
        "            for iteration in range(max_iterations):\n",
        "                best_neighbor_energy = float('inf')\n",
        "                best_flip_idx = -1\n",
        "\n",
        "                for i in range(self.n):\n",
        "                    if i in tabu_list and tabu_list[i] > iteration:\n",
        "                        continue\n",
        "\n",
        "                    x[i] = 1 - x[i]\n",
        "                    neighbor_energy = self.energy(x)\n",
        "                    x[i] = 1 - x[i]\n",
        "\n",
        "                    if neighbor_energy < best_neighbor_energy:\n",
        "                        best_neighbor_energy = neighbor_energy\n",
        "                        best_flip_idx = i\n",
        "\n",
        "                if best_flip_idx >= 0:\n",
        "                    x[best_flip_idx] = 1 - x[best_flip_idx]\n",
        "                    current_energy = best_neighbor_energy\n",
        "                    tabu_list[best_flip_idx] = iteration + tabu_tenure\n",
        "\n",
        "                    if current_energy < best_energy:\n",
        "                        best_x = x.copy()\n",
        "                        best_energy = current_energy\n",
        "\n",
        "            if best_energy < global_best_energy:\n",
        "                global_best_x = best_x\n",
        "                global_best_energy = best_energy\n",
        "\n",
        "        return global_best_x, global_best_energy\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# PART 3: GROUP BALANCING AND VALIDATION\n",
        "# ============================================================================\n",
        "\n",
        "def balance_groups(solution: np.ndarray, target_size: int = 50) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Adjust solution to have exactly target_size ones.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    solution : np.ndarray\n",
        "        Binary solution vector\n",
        "    target_size : int\n",
        "        Desired number of ones\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    balanced : np.ndarray\n",
        "        Balanced binary solution\n",
        "    \"\"\"\n",
        "    balanced = solution.copy()\n",
        "    current_size = int(balanced.sum())\n",
        "\n",
        "    if current_size == target_size:\n",
        "        return balanced\n",
        "\n",
        "    if current_size > target_size:\n",
        "        # Too many ones - flip some to zero\n",
        "        ones_idx = np.where(balanced == 1)[0]\n",
        "        flip_idx = np.random.choice(ones_idx, current_size - target_size, replace=False)\n",
        "        balanced[flip_idx] = 0\n",
        "    else:\n",
        "        # Too few ones - flip some to one\n",
        "        zeros_idx = np.where(balanced == 0)[0]\n",
        "        flip_idx = np.random.choice(zeros_idx, target_size - current_size, replace=False)\n",
        "        balanced[flip_idx] = 1\n",
        "\n",
        "    return balanced\n",
        "\n",
        "\n",
        "def validate_solution(group1: np.ndarray, group2: np.ndarray) -> Dict:\n",
        "    \"\"\"\n",
        "    Validate that the solution is correct.\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    validation : dict\n",
        "        Validation results\n",
        "    \"\"\"\n",
        "    n = len(group1)\n",
        "\n",
        "    validation = {\n",
        "        'valid': True,\n",
        "        'size_correct': group1.sum() == n // 2,\n",
        "        'complementary': np.array_equal(group2, 1 - group1),\n",
        "        'binary': np.all((group1 == 0) | (group1 == 1)),\n",
        "        'group1_size': int(group1.sum()),\n",
        "        'group2_size': int(group2.sum())\n",
        "    }\n",
        "\n",
        "    validation['valid'] = all([\n",
        "        validation['size_correct'],\n",
        "        validation['complementary'],\n",
        "        validation['binary']\n",
        "    ])\n",
        "\n",
        "    return validation\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# PART 4: MAIN PIPELINE\n",
        "# ============================================================================\n",
        "\n",
        "def solve_patient_matching(W: np.ndarray,\n",
        "                          rho: float = 0.5,\n",
        "                          lam_size: float = 3.0,\n",
        "                          n_runs: int = 5,\n",
        "                          use_gpu: bool = True,\n",
        "                          verbose: bool = False) -> Tuple[np.ndarray, np.ndarray]:\n",
        "    \"\"\"\n",
        "    Complete pipeline to solve patient matching problem.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    W : np.ndarray of shape (n, d)\n",
        "        Feature matrix (n patients, d features)\n",
        "    rho : float\n",
        "        Covariance weight in QUBO\n",
        "    lam_size : float\n",
        "        Group size penalty coefficient\n",
        "    n_runs : int\n",
        "        Number of solver runs\n",
        "    use_gpu : bool\n",
        "        Whether to use GPU if available\n",
        "    verbose : bool\n",
        "        Print progress\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    group1 : np.ndarray of shape (n,)\n",
        "        Binary array with exactly 50 ones\n",
        "    group2 : np.ndarray of shape (n,)\n",
        "        Binary array = 1 - group1\n",
        "    \"\"\"\n",
        "\n",
        "    n = W.shape[0]\n",
        "    target_size = n // 2\n",
        "\n",
        "    if verbose:\n",
        "        print(\"=\"*70)\n",
        "        print(\"PATIENT MATCHING PIPELINE\")\n",
        "        print(\"=\"*70)\n",
        "        print(f\"Number of patients: {n}\")\n",
        "        print(f\"Number of features: {W.shape[1]}\")\n",
        "        print(f\"Target group size: {target_size}\")\n",
        "        print(f\"Rho: {rho}\")\n",
        "        print(f\"Lambda (size penalty): {lam_size}\")\n",
        "\n",
        "    # Step 1: Build QUBO\n",
        "    if verbose:\n",
        "        print(\"\\n[1/4] Building QUBO matrix...\")\n",
        "    start_time = time.time()\n",
        "    Q = QUBO_formulation(W, rho=rho, lam_size=lam_size, normalize=True)\n",
        "    if verbose:\n",
        "        print(f\"      QUBO shape: {Q.shape}\")\n",
        "        print(f\"      Time: {time.time() - start_time:.2f}s\")\n",
        "\n",
        "    # Step 2: Solve with multiple methods\n",
        "    if verbose:\n",
        "        print(\"\\n[2/4] Solving with multiple methods...\")\n",
        "\n",
        "    all_solutions = []\n",
        "    all_energies = []\n",
        "\n",
        "    # Method 1: Simulated Annealing (GPU)\n",
        "    if use_gpu and torch.cuda.is_available():\n",
        "        if verbose:\n",
        "            print(\"\\n  Method 1: Simulated Annealing (GPU)\")\n",
        "        solver_sa = QUBOSimulatedAnnealing(Q, device='cuda')\n",
        "\n",
        "        for run in range(n_runs):\n",
        "            if verbose:\n",
        "                print(f\"    Run {run+1}/{n_runs}...\")\n",
        "            solution, energy = solver_sa.solve(\n",
        "                n_iterations=15000,\n",
        "                n_parallel=64,\n",
        "                verbose=False\n",
        "            )\n",
        "            all_solutions.append(solution)\n",
        "            all_energies.append(energy)\n",
        "            if verbose:\n",
        "                print(f\"      Energy: {energy:.4f}, Size: {solution.sum()}\")\n",
        "\n",
        "    # Method 2: Tabu Search (CPU)\n",
        "    if verbose:\n",
        "        print(\"\\n  Method 2: Tabu Search (CPU)\")\n",
        "    solver_tabu = QUBOTabuSearch(Q)\n",
        "\n",
        "    for run in range(min(3, n_runs)):  # Fewer runs for slower method\n",
        "        if verbose:\n",
        "            print(f\"    Run {run+1}/{min(3, n_runs)}...\")\n",
        "        solution, energy = solver_tabu.solve(\n",
        "            max_iterations=5000,\n",
        "            n_restarts=3,\n",
        "            verbose=False\n",
        "        )\n",
        "        all_solutions.append(solution)\n",
        "        all_energies.append(energy)\n",
        "        if verbose:\n",
        "            print(f\"      Energy: {energy:.4f}, Size: {solution.sum()}\")\n",
        "\n",
        "    # Step 3: Select best and balance\n",
        "    if verbose:\n",
        "        print(\"\\n[3/4] Selecting best solution and balancing groups...\")\n",
        "\n",
        "    best_idx = np.argmin(all_energies)\n",
        "    best_solution = all_solutions[best_idx]\n",
        "    best_energy = all_energies[best_idx]\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"      Best energy: {best_energy:.4f}\")\n",
        "        print(f\"      Original group size: {best_solution.sum()}\")\n",
        "\n",
        "    # Balance to exactly 50-50 split\n",
        "    group1 = balance_groups(best_solution, target_size=target_size)\n",
        "    group2 = 1 - group1\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"      Balanced group1 size: {group1.sum()}\")\n",
        "        print(f\"      Balanced group2 size: {group2.sum()}\")\n",
        "\n",
        "    # Step 4: Validate\n",
        "    if verbose:\n",
        "        print(\"\\n[4/4] Validating solution...\")\n",
        "\n",
        "    validation = validate_solution(group1, group2)\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"      Valid: {validation['valid']}\")\n",
        "        print(f\"      Size correct: {validation['size_correct']}\")\n",
        "        print(f\"      Complementary: {validation['complementary']}\")\n",
        "        print(f\"      Binary: {validation['binary']}\")\n",
        "\n",
        "    if not validation['valid']:\n",
        "        raise ValueError(\"Solution validation failed!\")\n",
        "\n",
        "    if verbose:\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"âœ“ SUCCESS!\")\n",
        "        print(\"=\"*70)\n",
        "        print(f\"Group 1: {group1.sum()} patients\")\n",
        "        print(f\"Group 2: {group2.sum()} patients\")\n",
        "        print(f\"Total time: {time.time() - start_time:.2f}s\")\n",
        "\n",
        "    return group1, group2\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "\n",
        "\n",
        "    W = w\n",
        "\n",
        "    print(\"Example Usage:\")\n",
        "    print(\"-\" * 70)\n",
        "\n",
        "    # Solve the matching problem\n",
        "    group1,group2 = solve_patient_matching(\n",
        "        W=W,\n",
        "        rho=0.5,\n",
        "        lam_size=3.0,\n",
        "        n_runs=5,\n",
        "        use_gpu=True,\n",
        "        verbose=True\n",
        "    )\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7BG3uSUaSYl",
        "outputId": "6a78d97c-29af-4733-e1cb-a7652d57f6a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example Usage:\n",
            "----------------------------------------------------------------------\n",
            "======================================================================\n",
            "PATIENT MATCHING PIPELINE\n",
            "======================================================================\n",
            "Number of patients: 100\n",
            "Number of features: 3\n",
            "Target group size: 50\n",
            "Rho: 0.5\n",
            "Lambda (size penalty): 3.0\n",
            "\n",
            "[1/4] Building QUBO matrix...\n",
            "      QUBO shape: (100, 100)\n",
            "      Time: 0.07s\n",
            "\n",
            "[2/4] Solving with multiple methods...\n",
            "\n",
            "  Method 1: Simulated Annealing (GPU)\n",
            "    Run 1/5...\n",
            "      Energy: -3827.0403, Size: 25\n",
            "    Run 2/5...\n",
            "      Energy: -3827.0935, Size: 25\n",
            "    Run 3/5...\n",
            "      Energy: -3827.1147, Size: 25\n",
            "    Run 4/5...\n",
            "      Energy: -3827.0845, Size: 25\n",
            "    Run 5/5...\n",
            "      Energy: -3827.1138, Size: 25\n",
            "\n",
            "  Method 2: Tabu Search (CPU)\n",
            "    Run 1/3...\n",
            "      Energy: -3826.9016, Size: 25\n",
            "    Run 2/3...\n",
            "      Energy: -3826.7739, Size: 25\n",
            "    Run 3/3...\n",
            "      Energy: -3827.1526, Size: 25\n",
            "\n",
            "[3/4] Selecting best solution and balancing groups...\n",
            "      Best energy: -3827.1526\n",
            "      Original group size: 25\n",
            "      Balanced group1 size: 50\n",
            "      Balanced group2 size: 50\n",
            "\n",
            "[4/4] Validating solution...\n",
            "      Valid: True\n",
            "      Size correct: True\n",
            "      Complementary: True\n",
            "      Binary: True\n",
            "\n",
            "======================================================================\n",
            "âœ“ SUCCESS!\n",
            "======================================================================\n",
            "Group 1: 50 patients\n",
            "Group 2: 50 patients\n",
            "Total time: 65.47s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "disc = trial.discrepancy(group1, group2)\n",
        "print(f\"Discrepancy: {disc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HjaRdlYmbA3m",
        "outputId": "2e0e15be-16b8-4454-cb82-643189351b3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discrepancy: 0.7573\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "disc = trial.discrepancy(group1, group2)\n",
        "print(f\"Discrepancy: {disc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTjeUXdKmPGj",
        "outputId": "b0ae68bb-989d-4e94-ff75-9aee469011a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discrepancy: 0.5201\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "D Wave Implementation"
      ],
      "metadata": {
        "id": "A25I6GuD1Y_q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dwave-ocean-sdk dwave-inspector"
      ],
      "metadata": {
        "id": "tVZRgpbE1eV0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from dwave.system import DWaveSampler, EmbeddingComposite, LeapHybridSampler\n",
        "from dimod import BinaryQuadraticModel\n",
        "import dwave.inspector\n",
        "\n",
        "with open(\"tokens/dwave_token.txt\", 'r') as file:\n",
        "    os.environ['DWAVE_API_TOKEN'] = file.read().strip()\n",
        "\n",
        "def create_sample_qubo(size=100):\n",
        "    np.random.seed(42)\n",
        "    Q = np.random.randn(size, size) * 10\n",
        "    Q = (Q + Q.T) / 2\n",
        "    return Q\n",
        "\n",
        "def qubo_to_dict(Q):\n",
        "    return {(i, j): Q[i, j] for i in range(Q.shape[0]) for j in range(i, Q.shape[1]) if Q[i, j] != 0}\n",
        "\n",
        "def solve_quantum(Q, num_reads=100, use_hybrid=False):\n",
        "    model = BinaryQuadraticModel.from_qubo(Q, offset=0.0)\n",
        "\n",
        "    with open(\"tokens/dwave_token.txt\", 'r') as file:\n",
        "        os.environ['DWAVE_API_TOKEN'] = file.read().strip()\n",
        "\n",
        "    if use_hybrid:\n",
        "        sampler = LeapHybridSampler()\n",
        "        print(\"Using Hybrid Solver...\")\n",
        "    else:\n",
        "        sampler = EmbeddingComposite(DWaveSampler())\n",
        "        print(\"Using Quantum Annealer with Embedding...\")\n",
        "\n",
        "    response = sampler.sample(model, num_reads=num_reads) if not use_hybrid else sampler.sample(model)\n",
        "\n",
        "    group1 = np.array(list(response.samples()[0].values()))\n",
        "    group2 = np.array([0 if group1[i]==1 else 1 for i in range(len(Q))])\n",
        "\n",
        "    return group1, group2, response\n",
        "\n",
        "def solve_qubo(qubo_dict, num_reads=100, chain_strength=None):\n",
        "    bqm = BinaryQuadraticModel.from_qubo(qubo_dict)\n",
        "    sampler = EmbeddingComposite(DWaveSampler())\n",
        "    print(f\"Variables: {len(bqm.variables)}, Interactions: {len(bqm.quadratic)}\")\n",
        "    return sampler.sample(bqm, num_reads=num_reads, chain_strength=chain_strength, label='QUBO_100x100')\n",
        "\n",
        "def solve_hybrid(qubo_dict):\n",
        "    bqm = BinaryQuadraticModel.from_qubo(qubo_dict)\n",
        "    return LeapHybridSampler().sample(bqm, label='QUBO_100x100_Hybrid')\n",
        "\n",
        "def analyze(sampleset, top_n=5):\n",
        "    print(f\"\\nBest Energy: {sampleset.first.energy:.4f}\")\n",
        "    print(f\"Total Samples: {len(sampleset)}\\n\")\n",
        "    for i, d in enumerate(sampleset.data(['sample', 'energy', 'num_occurrences'])[:top_n]):\n",
        "        print(f\"{i+1}. Energy: {d.energy:.4f}, Occurs: {d.num_occurrences}\")\n",
        "    return sampleset.first.sample, sampleset.first.energy\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    Q = QUBO_formulation(W, rho=rho, lam_size=lam_size, normalize=True)\n",
        "    qubo_dict = qubo_to_dict(Q)\n",
        "\n",
        "\n",
        "    print(\"\\n=== Quantum Annealer (EmbeddingComposite) ===\")\n",
        "    group1_qa, group2_qa, response_qa = solve_quantum(qubo_dict, num_reads=100, use_hybrid=False)\n",
        "    print(f\"Group1: {group1_qa[:10]}...\")\n",
        "    print(f\"Group2: {group2_qa[:10]}...\")\n",
        "    print(f\"Energy: {response_qa.first.energy:.4f}\")\n",
        "\n",
        "    print(\"\\n=== Hybrid Solver (LeapHybridSampler) ===\")\n",
        "    group1_hy, group2_hy, response_hy = solve_quantum(qubo_dict, use_hybrid=True)\n",
        "    print(f\"Group1: {group1_hy[:10]}...\")\n",
        "    print(f\"Group2: {group2_hy[:10]}...\")\n",
        "    print(f\"Energy: {response_hy.first.energy:.4f}\")\n",
        "\n",
        "    dwave.inspector.show(response_qa)"
      ],
      "metadata": {
        "id": "VhxzDlLKr6TQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}